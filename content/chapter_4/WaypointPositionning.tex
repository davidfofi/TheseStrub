\chapter{Waypoints positioning} 
\minitoc
To remind, the main objective is to propose a efficient path to can cover an area using a camera mounted on a UAV. In the solution proposed here is to in the first time, focus on optimize the position of a cameras set to fully cover an area. When a optimized position of the cameras set is found the position can be used as waypoints for an UAVs path. Indeed find an optimized position for each camera of a given set is primordial. The following section are dedicated to the optimization of it in order to have an efficient solution to place the waypoints.




%\section{An optimization problem.}

During the previous section the problem was already discussed as an optimization problem. The formulation of the problem was presented to can apply some optimization problems and also the complexity of the problem was disused in the section \ref{sec:OptimizationComplexity}.



\section{PSO and Random Selection }

The PSO (Particle Swarm Optimization) is an algorithm dedicated to the optimization problems. It is an stochastic algorithms form the family of evolutionary algorithms (see \ref{chap:EA}). 
The PSO is a relatively young compared then the other EA. It was developed by Russel Eberhart and James Kennedy in 1995 [148* bis]. The concept of PSO is to optimize iteratively a continuous non linear function. To do that the PSO is inspired by the behaviour of animals. As it append here form the bird flocking,fish schooling and swarming theory. These animals working in group to find food. 
The direction to take is not decide by one leader, but by all individuals of the swarm by relaying just few informations as what quantities of food their found. 
The swarm composed by numerous individuals became smarter and more efficient to reach their objective. 
The algorithm proposed by Russel Eberhart and James Kennedy in [148* bis] are directly inspired by these behaviours.

The methodologies used is to consider each individual or also called particles as a solution of the problems. The problems is optimized at each iteration. To do that each solution must be comparable and quantifiable. At each iteration, each particle have to be tested by a cost function in order to discriminate the best particles of the swarm. The cost function and the design of it has been detailed in the section \ref{chap:formulation}.
When the best particle is found at the end of an iteration, the other particles of set try to change their initial direction to converge to the best. 
Indeed the power of this algorithm is to have a very basic individuals behaviour. 
Each particles are guided by 3 behaviours.
 \begin{itemize}
 \item  This own velocity $V_k$. 
 \item  This own best solution $P_i$.
 \item  The best solution $P_g$.
\end{itemize}  

To have :
\begin{equation}
\begin{split}
 V_{k+1}= \omega V_k +b1(P_i -X_k)+b2(P_g-X_k)
\\
\mbox{ and } \\ X_{k+1}=X_k+V_{k+1}
\end{split}
\end{equation}

Where $\omega$ is the inertia. $b1$ is random value between 0 and $\phi_p$ and b2 is random value between 0 and $\phi_g$. $\phi_g$ and $\phi_p$  are the scaling factor to search away from the particleâ€™s best known position (Default: 0.5). 


-the initial dispersion of the particles 
- size swarm
- stoping criteria 
- inconvenient 


148 origine de PSO. 
PSO[84 8 33 143] 87 193* 194* 200* 201* 

228* 161* 158* 78 GA VS PSO

\section{GA VS PSO }\label{sec:GAvsPSO} 
fill with the jirs 
	\subsection{DoF Design of Experiment}
	\subsection{Result}
	\subsection{Explication}

\section{Hybrid GA PSO}
 76* 77* 78*
	\subsection{memetic ???}
		\subsubsection{DoF}
		\subsubsection{Result}
		\subsubsection{Conclusion}
		
\section{Experiment}
	\subsection{No obstacle }
	\subsection{Rectangle obstacle}
	\subsubsection{With mask}
	\subsection{For big area}
		\subsubsection{map 1}
		\subsubsection{map2 torcy}
		\subsubsection{map3 calvisson}
		


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 


